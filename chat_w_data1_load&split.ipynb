{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain: Chat with Your Data\n",
    "\n",
    "Main topics:<br>\n",
    "1. Retrieval Augmented Generation (RAG): common LLM application that retrieves contextual documents from external dataset - useful to ask question about specific documents (e.g. PDFs, videos, etc.)\n",
    "\n",
    "![Alt text](pics\\rag.png)\n",
    "\n",
    "2. Build chatbot that responds to queries based on content of your documents, rather than info learned from training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Loading\n",
    "\n",
    "LangChain has >80 unique loaders to provide access to diverse data sources, incl. audio and video\n",
    "\n",
    "Accessing: \n",
    "+ Websites\n",
    "+ Databases\n",
    "+ Youtube\n",
    "+ arXiv...\n",
    "\n",
    "Data Types:\n",
    "+ PDF\n",
    "+ HTML\n",
    "+ JSON\n",
    "+ Word, PowerPoint...\n",
    "\n",
    "-> Returns a list of 'Documents' objects\n",
    "\n",
    "![Alt text](pics\\loaders.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import openai\n",
    "\n",
    "sys.path.append('../..')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load PDFs\n",
    "\n",
    "Load PDF transcript from Andrew Ng's CS229 course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pypdf\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"docs/cs229_lectures/MachineLearning-Lecture01.pdf\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)\n",
    "\n",
    "# 22 pages in the pdf\n",
    "# Each page is a \"document\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A document contains page_content and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MachineLearning-Lecture01  \n",
      "Instructor (Andrew Ng):  Okay. Good morning. Welcome to CS229, the machine \n",
      "learning class. So what I wanna do today is ju st spend a little time going over the logistics \n",
      "of the class, and then we'll start to  talk a bit about machine learning.  \n",
      "By way of introduction, my name's  Andrew Ng and I'll be instru ctor for this class. And so \n",
      "I personally work in machine learning, and I' ve worked on it for about 15 years now, and \n",
      "I actually think that machine learning i\n"
     ]
    }
   ],
   "source": [
    "page = pages[0]\n",
    "print(page.page_content[0:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf', 'page': 0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install yt_dlp\n",
    "# pip install pydub\n",
    "# conda install -c conda-forge ffmpeg\n",
    "from langchain.document_loaders.generic import GenericLoader\n",
    "from langchain.document_loaders.parsers import OpenAIWhisperParser # speech-to-text model \n",
    "from langchain.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoader # load audio file from YT vid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=jGwO_UgTS7I\n",
      "[youtube] jGwO_UgTS7I: Downloading webpage\n",
      "[youtube] jGwO_UgTS7I: Downloading ios player API JSON\n",
      "[youtube] jGwO_UgTS7I: Downloading android player API JSON\n",
      "[youtube] jGwO_UgTS7I: Downloading m3u8 information\n",
      "[info] jGwO_UgTS7I: Downloading 1 format(s): 140\n",
      "[download] docs\\youtube\\Stanford CS229： Machine Learning Course, Lecture 1 - Andrew Ng (Autumn 2018).m4a has already been downloaded\n",
      "[download] 100% of   69.76MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Postprocessing: ffprobe and ffmpeg not found. Please install or provide the path using --ffmpeg-location\n"
     ]
    },
    {
     "ename": "DownloadError",
     "evalue": "ERROR: Postprocessing: ffprobe and ffmpeg not found. Please install or provide the path using --ffmpeg-location",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPostProcessingError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\I589795\\AppData\\Local\\anaconda3\\envs\\venv1\\Lib\\site-packages\\yt_dlp\\YoutubeDL.py:3464\u001b[0m, in \u001b[0;36mYoutubeDL.process_info\u001b[1;34m(self, info_dict)\u001b[0m\n\u001b[0;32m   3463\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3464\u001b[0m     replace_info_dict(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpost_process(dl_filename, info_dict, files_to_move))\n\u001b[0;32m   3465\u001b[0m \u001b[39mexcept\u001b[39;00m PostProcessingError \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\I589795\\AppData\\Local\\anaconda3\\envs\\venv1\\Lib\\site-packages\\yt_dlp\\YoutubeDL.py:3644\u001b[0m, in \u001b[0;36mYoutubeDL.post_process\u001b[1;34m(self, filename, info, files_to_move)\u001b[0m\n\u001b[0;32m   3643\u001b[0m info[\u001b[39m'\u001b[39m\u001b[39m__files_to_move\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m files_to_move \u001b[39mor\u001b[39;00m {}\n\u001b[1;32m-> 3644\u001b[0m info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_all_pps(\u001b[39m'\u001b[39m\u001b[39mpost_process\u001b[39m\u001b[39m'\u001b[39m, info, additional_pps\u001b[39m=\u001b[39minfo\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39m__postprocessors\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m   3645\u001b[0m info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_pp(MoveFilesAfterDownloadPP(\u001b[39mself\u001b[39m), info)\n",
      "File \u001b[1;32mc:\\Users\\I589795\\AppData\\Local\\anaconda3\\envs\\venv1\\Lib\\site-packages\\yt_dlp\\YoutubeDL.py:3626\u001b[0m, in \u001b[0;36mYoutubeDL.run_all_pps\u001b[1;34m(self, key, info, additional_pps)\u001b[0m\n\u001b[0;32m   3625\u001b[0m \u001b[39mfor\u001b[39;00m pp \u001b[39min\u001b[39;00m (additional_pps \u001b[39mor\u001b[39;00m []) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pps[key]:\n\u001b[1;32m-> 3626\u001b[0m     info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_pp(pp, info)\n\u001b[0;32m   3627\u001b[0m \u001b[39mreturn\u001b[39;00m info\n",
      "File \u001b[1;32mc:\\Users\\I589795\\AppData\\Local\\anaconda3\\envs\\venv1\\Lib\\site-packages\\yt_dlp\\YoutubeDL.py:3604\u001b[0m, in \u001b[0;36mYoutubeDL.run_pp\u001b[1;34m(self, pp, infodict)\u001b[0m\n\u001b[0;32m   3603\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3604\u001b[0m     files_to_delete, infodict \u001b[39m=\u001b[39m pp\u001b[39m.\u001b[39mrun(infodict)\n\u001b[0;32m   3605\u001b[0m \u001b[39mexcept\u001b[39;00m PostProcessingError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   3606\u001b[0m     \u001b[39m# Must be True and not 'only_download'\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\I589795\\AppData\\Local\\anaconda3\\envs\\venv1\\Lib\\site-packages\\yt_dlp\\postprocessor\\common.py:23\u001b[0m, in \u001b[0;36mPostProcessorMetaClass.run_wrapper.<locals>.run\u001b[1;34m(self, info, *args, **kwargs)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hook_progress({\u001b[39m'\u001b[39m\u001b[39mstatus\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mstarted\u001b[39m\u001b[39m'\u001b[39m}, info_copy)\n\u001b[1;32m---> 23\u001b[0m ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39m, info, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     24\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\I589795\\AppData\\Local\\anaconda3\\envs\\venv1\\Lib\\site-packages\\yt_dlp\\postprocessor\\common.py:128\u001b[0m, in \u001b[0;36mPostProcessor._restrict_to.<locals>.decorator.<locals>.wrapper\u001b[1;34m(self, info)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39mif\u001b[39;00m allowed[format_type]:\n\u001b[1;32m--> 128\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39m, info)\n\u001b[0;32m    129\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\I589795\\AppData\\Local\\anaconda3\\envs\\venv1\\Lib\\site-packages\\yt_dlp\\postprocessor\\ffmpeg.py:493\u001b[0m, in \u001b[0;36mFFmpegExtractAudioPP.run\u001b[1;34m(self, information)\u001b[0m\n\u001b[0;32m    491\u001b[0m     \u001b[39mreturn\u001b[39;00m [], information\n\u001b[1;32m--> 493\u001b[0m filecodec \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_audio_codec(path)\n\u001b[0;32m    494\u001b[0m \u001b[39mif\u001b[39;00m filecodec \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\I589795\\AppData\\Local\\anaconda3\\envs\\venv1\\Lib\\site-packages\\yt_dlp\\postprocessor\\ffmpeg.py:241\u001b[0m, in \u001b[0;36mFFmpegPostProcessor.get_audio_codec\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprobe_available \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mavailable:\n\u001b[1;32m--> 241\u001b[0m     \u001b[39mraise\u001b[39;00m PostProcessingError(\u001b[39m'\u001b[39m\u001b[39mffprobe and ffmpeg not found. Please install or provide the path using --ffmpeg-location\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    242\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;31mPostProcessingError\u001b[0m: ffprobe and ffmpeg not found. Please install or provide the path using --ffmpeg-location",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mDownloadError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\I589795\\Documents\\Machine Learning\\LLM\\ChatGPT-based\\LLM-LangChain-ChatWithYourData\\chatwithyourdata.ipynb Cell 12\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/I589795/Documents/Machine%20Learning/LLM/ChatGPT-based/LLM-LangChain-ChatWithYourData/chatwithyourdata.ipynb#X25sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m save_dir\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdocs/youtube/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/I589795/Documents/Machine%20Learning/LLM/ChatGPT-based/LLM-LangChain-ChatWithYourData/chatwithyourdata.ipynb#X25sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m loader \u001b[39m=\u001b[39m GenericLoader(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/I589795/Documents/Machine%20Learning/LLM/ChatGPT-based/LLM-LangChain-ChatWithYourData/chatwithyourdata.ipynb#X25sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     YoutubeAudioLoader([url],save_dir),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/I589795/Documents/Machine%20Learning/LLM/ChatGPT-based/LLM-LangChain-ChatWithYourData/chatwithyourdata.ipynb#X25sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     OpenAIWhisperParser()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/I589795/Documents/Machine%20Learning/LLM/ChatGPT-based/LLM-LangChain-ChatWithYourData/chatwithyourdata.ipynb#X25sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m )\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/I589795/Documents/Machine%20Learning/LLM/ChatGPT-based/LLM-LangChain-ChatWithYourData/chatwithyourdata.ipynb#X25sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m docs \u001b[39m=\u001b[39m loader\u001b[39m.\u001b[39mload()\n",
      "File \u001b[1;32mc:\\Users\\I589795\\AppData\\Local\\anaconda3\\envs\\venv1\\Lib\\site-packages\\langchain\\document_loaders\\generic.py:90\u001b[0m, in \u001b[0;36mGenericLoader.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Document]:\n\u001b[0;32m     89\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Load all documents.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 90\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlazy_load())\n",
      "File \u001b[1;32mc:\\Users\\I589795\\AppData\\Local\\anaconda3\\envs\\venv1\\Lib\\site-packages\\langchain\\document_loaders\\generic.py:85\u001b[0m, in \u001b[0;36mGenericLoader.lazy_load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlazy_load\u001b[39m(\n\u001b[0;32m     82\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m     83\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[Document]:\n\u001b[0;32m     84\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Load documents lazily. Use this when working at a large scale.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 85\u001b[0m     \u001b[39mfor\u001b[39;00m blob \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblob_loader\u001b[39m.\u001b[39myield_blobs():\n\u001b[0;32m     86\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblob_parser\u001b[39m.\u001b[39mlazy_parse(blob)\n",
      "File \u001b[1;32mc:\\Users\\I589795\\AppData\\Local\\anaconda3\\envs\\venv1\\Lib\\site-packages\\langchain\\document_loaders\\blob_loaders\\youtube_audio.py:45\u001b[0m, in \u001b[0;36mYoutubeAudioLoader.yield_blobs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[39mfor\u001b[39;00m url \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39murls:\n\u001b[0;32m     43\u001b[0m     \u001b[39m# Download file\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     \u001b[39mwith\u001b[39;00m yt_dlp\u001b[39m.\u001b[39mYoutubeDL(ydl_opts) \u001b[39mas\u001b[39;00m ydl:\n\u001b[1;32m---> 45\u001b[0m         ydl\u001b[39m.\u001b[39mdownload(url)\n\u001b[0;32m     47\u001b[0m \u001b[39m# Yield the written blobs\u001b[39;00m\n\u001b[0;32m     48\u001b[0m loader \u001b[39m=\u001b[39m FileSystemBlobLoader(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_dir, glob\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m*.m4a\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\I589795\\AppData\\Local\\anaconda3\\envs\\venv1\\Lib\\site-packages\\yt_dlp\\YoutubeDL.py:3510\u001b[0m, in \u001b[0;36mYoutubeDL.download\u001b[1;34m(self, url_list)\u001b[0m\n\u001b[0;32m   3507\u001b[0m     \u001b[39mraise\u001b[39;00m SameFileError(outtmpl)\n\u001b[0;32m   3509\u001b[0m \u001b[39mfor\u001b[39;00m url \u001b[39min\u001b[39;00m url_list:\n\u001b[1;32m-> 3510\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__download_wrapper(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mextract_info)(\n\u001b[0;32m   3511\u001b[0m         url, force_generic_extractor\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mforce_generic_extractor\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m))\n\u001b[0;32m   3513\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_download_retcode\n",
      "File \u001b[1;32mc:\\Users\\I589795\\AppData\\Local\\anaconda3\\envs\\venv1\\Lib\\site-packages\\yt_dlp\\YoutubeDL.py:3485\u001b[0m, in \u001b[0;36mYoutubeDL.__download_wrapper.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   3482\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m   3483\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   3484\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3485\u001b[0m         res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   3486\u001b[0m     \u001b[39mexcept\u001b[39;00m UnavailableVideoError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   3487\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreport_error(e)\n",
      "File \u001b[1;32mc:\\Users\\I589795\\AppData\\Local\\anaconda3\\envs\\venv1\\Lib\\site-packages\\yt_dlp\\YoutubeDL.py:1556\u001b[0m, in \u001b[0;36mYoutubeDL.extract_info\u001b[1;34m(self, url, download, ie_key, extra_info, process, force_generic_extractor)\u001b[0m\n\u001b[0;32m   1554\u001b[0m             \u001b[39mraise\u001b[39;00m ExistingVideoReached()\n\u001b[0;32m   1555\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m-> 1556\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__extract_info(url, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_info_extractor(key), download, extra_info, process)\n\u001b[0;32m   1557\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1558\u001b[0m     extractors_restricted \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mallowed_extractors\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39mNone\u001b[39;00m, [\u001b[39m'\u001b[39m\u001b[39mdefault\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\I589795\\AppData\\Local\\anaconda3\\envs\\venv1\\Lib\\site-packages\\yt_dlp\\YoutubeDL.py:1567\u001b[0m, in \u001b[0;36mYoutubeDL._handle_extraction_exceptions.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1565\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m   1566\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1567\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1568\u001b[0m     \u001b[39mexcept\u001b[39;00m (DownloadCancelled, LazyList\u001b[39m.\u001b[39mIndexError, PagedList\u001b[39m.\u001b[39mIndexError):\n\u001b[0;32m   1569\u001b[0m         \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\I589795\\AppData\\Local\\anaconda3\\envs\\venv1\\Lib\\site-packages\\yt_dlp\\YoutubeDL.py:1723\u001b[0m, in \u001b[0;36mYoutubeDL.__extract_info\u001b[1;34m(self, url, ie, download, extra_info, process)\u001b[0m\n\u001b[0;32m   1721\u001b[0m \u001b[39mif\u001b[39;00m process:\n\u001b[0;32m   1722\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wait_for_video(ie_result)\n\u001b[1;32m-> 1723\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_ie_result(ie_result, download, extra_info)\n\u001b[0;32m   1724\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1725\u001b[0m     \u001b[39mreturn\u001b[39;00m ie_result\n",
      "File \u001b[1;32mc:\\Users\\I589795\\AppData\\Local\\anaconda3\\envs\\venv1\\Lib\\site-packages\\yt_dlp\\YoutubeDL.py:1782\u001b[0m, in \u001b[0;36mYoutubeDL.process_ie_result\u001b[1;34m(self, ie_result, download, extra_info)\u001b[0m\n\u001b[0;32m   1780\u001b[0m \u001b[39mif\u001b[39;00m result_type \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mvideo\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m   1781\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_extra_info(ie_result, extra_info)\n\u001b[1;32m-> 1782\u001b[0m     ie_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_video_result(ie_result, download\u001b[39m=\u001b[39mdownload)\n\u001b[0;32m   1783\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_pending_errors(ie_result)\n\u001b[0;32m   1784\u001b[0m     additional_urls \u001b[39m=\u001b[39m (ie_result \u001b[39mor\u001b[39;00m {})\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39madditional_urls\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\I589795\\AppData\\Local\\anaconda3\\envs\\venv1\\Lib\\site-packages\\yt_dlp\\YoutubeDL.py:2921\u001b[0m, in \u001b[0;36mYoutubeDL.process_video_result\u001b[1;34m(self, info_dict, download)\u001b[0m\n\u001b[0;32m   2919\u001b[0m downloaded_formats\u001b[39m.\u001b[39mappend(new_info)\n\u001b[0;32m   2920\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 2921\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_info(new_info)\n\u001b[0;32m   2922\u001b[0m \u001b[39mexcept\u001b[39;00m MaxDownloadsReached:\n\u001b[0;32m   2923\u001b[0m     max_downloads_reached \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\I589795\\AppData\\Local\\anaconda3\\envs\\venv1\\Lib\\site-packages\\yt_dlp\\YoutubeDL.py:3466\u001b[0m, in \u001b[0;36mYoutubeDL.process_info\u001b[1;34m(self, info_dict)\u001b[0m\n\u001b[0;32m   3464\u001b[0m     replace_info_dict(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpost_process(dl_filename, info_dict, files_to_move))\n\u001b[0;32m   3465\u001b[0m \u001b[39mexcept\u001b[39;00m PostProcessingError \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3466\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreport_error(\u001b[39m'\u001b[39m\u001b[39mPostprocessing: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m \u001b[39mstr\u001b[39m(err))\n\u001b[0;32m   3467\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m   3468\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\I589795\\AppData\\Local\\anaconda3\\envs\\venv1\\Lib\\site-packages\\yt_dlp\\YoutubeDL.py:1045\u001b[0m, in \u001b[0;36mYoutubeDL.report_error\u001b[1;34m(self, message, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1040\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreport_error\u001b[39m(\u001b[39mself\u001b[39m, message, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   1041\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[39m    Do the same as trouble, but prefixes the message with 'ERROR:', colored\u001b[39;00m\n\u001b[0;32m   1043\u001b[0m \u001b[39m    in red if stderr is a tty file.\u001b[39;00m\n\u001b[0;32m   1044\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[1;32m-> 1045\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrouble(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_err(\u001b[39m\"\u001b[39m\u001b[39mERROR:\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m \u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mStyles\u001b[39m.\u001b[39mERROR)\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mmessage\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\I589795\\AppData\\Local\\anaconda3\\envs\\venv1\\Lib\\site-packages\\yt_dlp\\YoutubeDL.py:984\u001b[0m, in \u001b[0;36mYoutubeDL.trouble\u001b[1;34m(self, message, tb, is_error)\u001b[0m\n\u001b[0;32m    982\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    983\u001b[0m         exc_info \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39mexc_info()\n\u001b[1;32m--> 984\u001b[0m     \u001b[39mraise\u001b[39;00m DownloadError(message, exc_info)\n\u001b[0;32m    985\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_download_retcode \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[1;31mDownloadError\u001b[0m: ERROR: Postprocessing: ffprobe and ffmpeg not found. Please install or provide the path using --ffmpeg-location"
     ]
    }
   ],
   "source": [
    "# Save YT vid in specified directory\n",
    "url=\"https://www.youtube.com/watch?v=jGwO_UgTS7I\"\n",
    "save_dir=\"docs/youtube/\"\n",
    "\n",
    "loader = GenericLoader(\n",
    "    YoutubeAudioLoader([url],save_dir),\n",
    "    OpenAIWhisperParser()\n",
    ")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[0].page_content[0:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://github.com/basecamp/handbook/blob/master/37signals-is-you.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "handbook/37signals-is-you.md at master · basecamp/handbook · GitHub\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Skip to content\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Toggle navigation\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            Sign up\n",
      "          \n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        Product\n",
      "        \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Actions\n",
      "        Automate any workflow\n",
      "      \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Packages\n",
      "        Host and manage packages\n",
      "      \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Security\n",
      "        Find and fix vulnerabilities\n",
      "      \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Code\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notion\n",
    "\n",
    "Follow steps here: https://python.langchain.com/docs/integrations/document_loaders/notion\n",
    " for an example Notion site such as this one: https://www.notion.so/Blendle-s-Employee-Handbook-41828bca9bb043e9ab39e12adc9799c8\n",
    "\n",
    "+ Duplicate the page into your own Notion space and export as Markdown / CSV.\n",
    "+ Unzip it and save it as a folder that contains the markdown file for the Notion page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import NotionDirectoryLoader\n",
    "loader = NotionDirectoryLoader(\"docs/Notion_DB\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Blendle's Employee Handbook\n",
      "\n",
      "This is a living document with everything we've learned working with people while running a startup. And, of course, we continue to learn. Therefore it's a document that\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[0:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': \"docs\\\\Notion_DB\\\\Blendle's Employee Handbook 41828bca9bb043e9ab39e12adc9799c8.md\"}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Splitting\n",
    "\n",
    "Split the documents into smaller chunks to enable retrieval of most relevant data\n",
    "\n",
    "- Split into semantically relevant and meaningful chunks\n",
    "\n",
    "- Text splitters in LangChain involves splitting on chunks with specified chunk size and some overlap\n",
    "  + Chunk size: Passing a length function to measure the size of the chunk - units are characters or tokens\n",
    "  + Chunk overlap: Allow same piece of context at the end of one chunk and at the start of the other - consistency\n",
    "\n",
    "![Alt text](pics\\splitters.png)\n",
    "\n",
    "![Alt text](pics\\splitter_type.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Character Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size =26\n",
    "chunk_overlap = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap\n",
    ")\n",
    "\n",
    "# Split on a single character - by default: split on newline character\n",
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcdefghijklmnopqrstuvwxyz']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = 'abcdefghijklmnopqrstuvwxyz'\n",
    "r_splitter.split_text(text1)\n",
    "# doesn't split text above since the text length = chunk size = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcdefghijklmnopqrstuvwxyz', 'wxyzabcdefg']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2 = 'abcdefghijklmnopqrstuvwxyzabcdefg'\n",
    "r_splitter.split_text(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a b c d e f g h i j k l m', 'l m n o p q r s t u v w x', 'w x y z']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text3 = \"a b c d e f g h i j k l m n o p q r s t u v w x y z\"\n",
    "r_splitter.split_text(text3)\n",
    "# space count as a character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a b c d e f g h i j k l m n o p q r s t u v w x y z']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_splitter.split_text(text3)\n",
    "# Doesn't even split\n",
    "# character splitter splits on a single character - default: newline character\n",
    "# no newline in the text, thus, no split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a b c d e f g h i j k l m', 'l m n o p q r s t u v w x', 'w x y z']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    separator = ' ' # set separator to be empty space\n",
    ")\n",
    "c_splitter.split_text(text3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recursive Split\n",
    "\n",
    "`RecursiveCharacterTextSplitter` is recommended for generic text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_text = \"\"\"When writing documents, writers will use document structure to group content. \\\n",
    "This can convey to the reader, which idea's are related. For example, closely related ideas \\\n",
    "are in sentances. Similar ideas are in paragraphs. Paragraphs form a document. \\n\\n  \\\n",
    "Paragraphs are often delimited with a carriage return or two carriage returns. \\\n",
    "Carriage returns are the \"backslash n\" you see embedded in this string. \\\n",
    "Sentences have a period at the end, but also, have a space.\\\n",
    "and words are separated by space.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "496"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=450,\n",
    "    chunk_overlap=0,\n",
    "    separator = ' '\n",
    ")\n",
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=450,\n",
    "    chunk_overlap=0, \n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"] \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['When writing documents, writers will use document structure to group content. This can convey to the reader, which idea\\'s are related. For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document. \\n\\n Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this string. Sentences have a period at the end, but also,',\n",
       " 'have a space.and words are separated by space.']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related. For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.\",\n",
       " 'Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this string. Sentences have a period at the end, but also, have a space.and words are separated by space.']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related. For example,\",\n",
       " 'closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.',\n",
       " 'Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this',\n",
       " 'string. Sentences have a period at the end, but also, have a space.and words are separated by space.']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reduce chunk size even more and add a period to the separators i.e. split between sentences\n",
    "\n",
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"\\. \", \" \", \"\"]\n",
    ")\n",
    "r_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related. For example,\",\n",
       " 'closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.',\n",
       " 'Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this',\n",
       " 'string. Sentences have a period at the end, but also, have a space.and words are separated by space.']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add more punctuations\n",
    "\n",
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"]\n",
    ")\n",
    "r_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split on PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"docs/cs229_lectures/MachineLearning-Lecture01.pdf\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=150,\n",
    "    length_function=len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)\n",
    "\n",
    "# More documents than pages after the split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split on Notion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import NotionDirectoryLoader\n",
    "loader = NotionDirectoryLoader(\"docs/Notion_DB\")\n",
    "notion_db = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = text_splitter.split_documents(notion_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(notion_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)\n",
    "\n",
    "# More documents after the split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token Split\n",
    "\n",
    "LLMs often have context windows designated in tokens. Tokens are often ~4 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import TokenTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = TokenTextSplitter(chunk_size=1, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foo', ' bar', ' b', 'az', 'zy', 'foo']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = \"foo bar bazzyfoo\"\n",
    "\n",
    "text_splitter.split_text(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = TokenTextSplitter(chunk_size=10, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=' is ju st spend a little time going over the', metadata={'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf', 'page': 0})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = text_splitter.split_documents(pages)\n",
    "\n",
    "docs[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf', 'page': 0}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context Aware Split\n",
    "Chunking aims to keep text with common context together.\n",
    "\n",
    "A text splitting often uses sentences or other delimiters to keep related text together but many documents (such as Markdown) have structure (headers) that can be explicitly used in splitting.\n",
    "\n",
    "We can use `MarkdownHeaderTextSplitter` to preserve header metadata in our chunks, as show below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import NotionDirectoryLoader\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_document = \"\"\"# Title\\n\\n \\\n",
    "## Chapter 1\\n\\n \\\n",
    "Hi this is Jim\\n\\n Hi this is Joe\\n\\n \\\n",
    "### Section \\n\\n \\\n",
    "Hi this is Lance \\n\\n \n",
    "## Chapter 2\\n\\n \\\n",
    "Hi this is Molly\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "md_header_splits = markdown_splitter.split_text(markdown_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Hi this is Jim  \\nHi this is Joe', metadata={'Header 1': 'Title', 'Header 2': 'Chapter 1'})"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_header_splits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Hi this is Lance', metadata={'Header 1': 'Title', 'Header 2': 'Chapter 1', 'Header 3': 'Section'})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_header_splits[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Notion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = NotionDirectoryLoader(\"docs/Notion_DB\")\n",
    "docs = loader.load()\n",
    "txt = ' '.join([d.page_content for d in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "]\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_header_splits = markdown_splitter.split_text(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=\"This is a living document with everything we've learned working with people while running a startup. And, of course, we continue to learn. Therefore it's a document that will continue to change.  \\n**Everything related to working at Blendle and the people of Blendle, made public.**  \\nThese are the lessons from three years of working with the people of Blendle. It contains everything from [how our leaders lead](https://www.notion.so/ecfb7e647136468a9a0a32f1771a8f52?pvs=21) to [how we increase salaries](https://www.notion.so/Salary-Review-e11b6161c6d34f5c9568bb3e83ed96b6?pvs=21), from [how we hire](https://www.notion.so/Hiring-451bbcfe8d9b49438c0633326bb7af0a?pvs=21) and [fire](https://www.notion.so/Firing-5567687a2000496b8412e53cd58eed9d?pvs=21) to [how we think people should give each other feedback](https://www.notion.so/Our-Feedback-Process-eb64f1de796b4350aeab3bc068e3801f?pvs=21) — and much more.  \\nWe've made this document public because we want to learn from you. We're very much interested in your feedback (including weeding out typo's and Dunglish ;)). Email us at hr@blendle.com. If you're starting your own company or if you're curious as to how we do things at Blendle, we hope that our employee handbook inspires you.  \\nIf you want to work at Blendle you can check our [job ads here](https://blendle.homerun.co/). If you want to be kept in the loop about Blendle, you can sign up for [our behind the scenes newsletter](https://blendle.homerun.co/yes-keep-me-posted/tr/apply?token=8092d4128c306003d97dd3821bad06f2).\", metadata={'Header 1': \"Blendle's Employee Handbook\"})"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_header_splits[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings & Vector Stores\n",
    "\n",
    "Check notebook 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval\n",
    "\n",
    "Check notebook 3\n",
    "\n",
    "Retrieval Augmented Generation (RAG): common LLM application that retrieves contextual documents from external dataset - useful to ask question about specific documents (e.g. PDFs, videos, etc.)\n",
    "\n",
    "![Alt text](pics\\rag.png)\n",
    "\n",
    "\n",
    "1. Methods for accessing/indexing data in vector store\n",
    "- Basic semantic similarity\n",
    "\n",
    "- Maximum marginal relevance (MMR)\n",
    "  + Not always want to choose the most similar responses - get add'l information\n",
    "\n",
    "  + MMR algorithm: \n",
    "    Query the vector store -> choose the `fetch_k` most similar responses -> within the responses, choose the `k` most diverse\n",
    "\n",
    "- Including Metadata<br>\n",
    "<br>\n",
    "\n",
    "2. LLM Aided Retrieval\n",
    "\n",
    "- SelfQuery: Use LLM to split user question into 2 things: a filter & a search term - useful to filter results based on metadata\n",
    "\n",
    "![Alt text](pics\\selfquery.png)\n",
    "\n",
    "- Compression: Run all documents through LLM & extract most relevant segments \n",
    "  -> pass only the most relevant segments into final language model call\n",
    "\n",
    "![Alt text](pics\\compress.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "persist_directory = 'docs/chroma/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorstore retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity Search\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum marginal relevance: Addressing Diversity\n",
    "\n",
    "`Maximum marginal relevance` strives to achieve both relevance to the query *and diversity* among the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with metadata: Addressing Specificity\n",
    "\n",
    "Many vectorstores support operations on `metadata`.\n",
    "\n",
    "`metadata` provides context for each embedded chunk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM-aided Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Self-query retriever: Using metadata\n",
    "\n",
    "But we have an interesting challenge: we often want to infer the metadata from the query itself.\n",
    "\n",
    "To address this, we can use `SelfQueryRetriever`, which uses an LLM to extract:\n",
    " \n",
    "1. The `query` string to use for vector search\n",
    "2. A metadata filter to pass in\n",
    "\n",
    "Most vector databases support metadata filters, so this doesn't require any new databases or indexes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compression\n",
    "\n",
    "Another approach for improving the quality of retrieved docs is compression.\n",
    "\n",
    "Information most relevant to a query may be buried in a document with a lot of irrelevant text. \n",
    "\n",
    "Passing that full document through your application can lead to more expensive LLM calls and poorer responses.\n",
    "\n",
    "Contextual compression is meant to fix this. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining various techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other types of retrieval\n",
    "\n",
    "It's worth noting that vectordb as not the only kind of tool to retrieve documents. \n",
    "\n",
    "The `LangChain` retriever abstraction includes other ways to retrieve documents, such as TF-IDF or SVM."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
